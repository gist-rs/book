{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oRhTab-3Isg"
      },
      "source": [
        "## Fine-tuning Mistral 7b with AutoTrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhDioAdc3ML5"
      },
      "source": [
        "Setup Runtime\n",
        "For fine-tuning Llama, a GPU instance is essential. Follow the directions below:\n",
        "\n",
        "- Go to `Runtime` (located in the top menu bar).\n",
        "- Select `Change Runtime Type`.\n",
        "- Choose `T4 GPU` (or a comparable option)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJZt3QI73kWF"
      },
      "source": [
        "### Step 1: Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgvqeBz_3XvO",
        "outputId": "96376e39-7fe6-4d68-fe4b-eb5d8f3a3f8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas autotrain-advanced ipywidgets -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepspeed in ./.venv/lib/python3.10/site-packages (0.14.0)\n",
            "Requirement already satisfied: hjson in ./.venv/lib/python3.10/site-packages (from deepspeed) (3.1.0)\n",
            "Requirement already satisfied: ninja in ./.venv/lib/python3.10/site-packages (from deepspeed) (1.11.1.1)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from deepspeed) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from deepspeed) (23.1)\n",
            "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from deepspeed) (5.9.8)\n",
            "Requirement already satisfied: py-cpuinfo in ./.venv/lib/python3.10/site-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic in ./.venv/lib/python3.10/site-packages (from deepspeed) (2.4.2)\n",
            "Requirement already satisfied: pynvml in ./.venv/lib/python3.10/site-packages (from deepspeed) (11.5.0)\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (from deepspeed) (2.2.1)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from deepspeed) (4.65.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic->deepspeed) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.10.1 in ./.venv/lib/python3.10/site-packages (from pydantic->deepspeed) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.10/site-packages (from pydantic->deepspeed) (4.10.0)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (3.1.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (2.2.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (11.4.5.107)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (3.13.1)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (2.19.3)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (10.3.2.106)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (11.0.2.54)\n",
            "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (1.12)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch->deepspeed) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch->deepspeed) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->torch->deepspeed) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "!DS_BUILD_CPU_ADAM=1\n",
        "%pip install deepspeed -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2024-03-14 18:38:39,761] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "--------------------------------------------------\n",
            "DeepSpeed C++/CUDA extension op report\n",
            "--------------------------------------------------\n",
            "NOTE: Ops not installed will be just-in-time (JIT) compiled at\n",
            "      runtime if needed. Op compatibility means that your system\n",
            "      meet the required dependencies to JIT install the op.\n",
            "--------------------------------------------------\n",
            "JIT compiled ops requires ninja\n",
            "ninja .................. \u001b[92m[OKAY]\u001b[0m\n",
            "--------------------------------------------------\n",
            "op name ................ installed .. compatible\n",
            "--------------------------------------------------\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "async_io ............... \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
            "fused_adam ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "cpu_adam ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "cpu_adagrad ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "cpu_lion ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "evoformer_attn ......... \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
            "fused_lamb ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "fused_lion ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "inference_core_ops ..... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "cutlass_ops ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "transformer_inference .. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "quantizer .............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "ragged_device_ops ...... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "ragged_ops ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "random_ltd ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible\n",
            "sparse_attn ............ \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
            "spatial_inference ...... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "transformer ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "stochastic_transformer . \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "--------------------------------------------------\n",
            "DeepSpeed general environment info:\n",
            "torch install path ............... ['/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch']\n",
            "torch version .................... 2.2.1+cu121\n",
            "deepspeed install path ........... ['/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed']\n",
            "deepspeed info ................... 0.14.0, unknown, unknown\n",
            "torch cuda version ............... 12.1\n",
            "torch hip version ................ None\n",
            "nvcc version ..................... 12.3\n",
            "deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1\n",
            "shared memory (/dev/shm) size .... 7.75 GB\n"
          ]
        }
      ],
      "source": [
        "!python -m deepspeed.env_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwStofw4257S",
        "outputId": "3c3881f0-9bd5-442f-dd3a-b363cc8d3c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[1mINFO    Installing latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest PyTorch\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest PyTorch\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!autotrain setup --update-torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-zXccJMZEx2"
      },
      "source": [
        "## Step 2: Connect to HuggingFace for Model Upload\n",
        "\n",
        "### Logging to Hugging Face\n",
        "To make sure the model can be uploaded to be used for Inference, it's necessary to log in to the Hugging Face hub.\n",
        "\n",
        "### Getting a Hugging Face token\n",
        "Steps:\n",
        "\n",
        "1. Navigate to this URL: https://huggingface.co/settings/tokens\n",
        "2. Create a write `token` and copy it to your clipboard\n",
        "3. Run the code below and enter your `token`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "93721b72963843db8afd2dc95b1a7e26",
            "3c4c437c3be348a6beaa549a070e7d03",
            "bef331d1317e4dca8423b41d9a4d5a46",
            "fd8eb83e711f4efeb5392159094979ee",
            "361f03f842874570ba0f5a7992ef85bb",
            "da5b0da670514701962d1fb278d2c806",
            "229eb3fe560b47cfaf90bd897d0356a3",
            "2488b59a84c4450a87d03d1a7416131a",
            "aba01680bd644852bdd01943fe6ff3a8",
            "32368ce026824d4faad5f96bb523b1ef",
            "6c9bfecb5c7d4218b905c5d9d1a94e67",
            "cdcf8ddbe33d443ebb8e746da30ac0e7",
            "0394a80f33694ddcaac86d11eb55dfba",
            "2087238355ef44719f296fa797fdd1a4",
            "3a25c5df13944295882f0114971dad95",
            "9c9e13827ccd49c28eb7e4b5b7bce367",
            "d65e536585574e1ebbe7dc596e5fff5b",
            "1878c66b2eae453a864ffead4070b1b1",
            "07a86a9d6045490582005ae3dc6235b4",
            "26203a05198d4ceeacbf5e773709f351",
            "1b54ffd23ba74eeebd9c469f440fb681",
            "6b08ab9f42604d50b75ca79953cdb513",
            "da126394b0454dfa92ead879aa4d05f8",
            "cdad03b3eb6f4b8498d4c095ef4bd77c",
            "3ea83882b0c24fc6bdc55ec477e8d966",
            "9cee18be45e147d094a9f3d563e43deb",
            "c7a697bfe78e4ef3ba7c086c6a7dc9a0",
            "3e3a59c9cd1e4bab9a7134b3ed460a70",
            "13f4a118e7ef4a148bde03a6e84e8aa3",
            "da203394bbcb4a3a98ccf00c99c8397c",
            "e72159dd38c04fda9b6944b21ef7ee18",
            "3be1673dc1ce401f9bf74665671fe25e"
          ]
        },
        "id": "VzMLmLP86Ub-",
        "outputId": "dad1be39-2a4b-4979-d08c-6254bb496948"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16158c29c3464cd8b00314b30e995e01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY932JBNZmtA"
      },
      "source": [
        "## Step 3: Upload your dataset\n",
        "\n",
        "Add your data set to the root directory in the Colab under the name train.csv. The AutoTrain command will look for your data there under that name.\n",
        "\n",
        "#### Don't have a data set and want to try finetuning on an example data set?\n",
        "If you don't have a dataset you can run these commands below to get an example data set and save it to train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JxTn4r_YZdkY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'finetune-llama-2'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 70 (delta 38), reused 48 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (70/70), 25.13 KiB | 5.03 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n",
            "/home/katopz/book/src/ml/finetuning/sft/finetune-llama-2\n",
            "/home/katopz/book/src/ml/finetuning/sft\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/joshbickett/finetune-llama-2.git\n",
        "%cd finetune-llama-2\n",
        "%mv train.csv ../train.csv\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1849
        },
        "id": "NUb-rkeoZzZ6",
        "outputId": "9dad4111-a670-4801-ba9c-07da36e93884"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Concept</th>\n",
              "      <th>Funny Description Prompt</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A cactus at a dance party</td>\n",
              "      <td>A cactus, wearing disco lights and surrounded ...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A robot on a first date</td>\n",
              "      <td>A robot, with a bouquet of USB cables, nervous...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A snail at a speed contest</td>\n",
              "      <td>A snail, with a mini rocket booster, confident...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A penguin at a beach party</td>\n",
              "      <td>A penguin, with sunscreen and a surfboard, try...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A cloud in a bad mood</td>\n",
              "      <td>A cloud, grumbling and dropping mini lightning...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>A donut feeling the hole emptiness</td>\n",
              "      <td>A donut, in existential bakery therapy, ponder...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>A pineapple with a prickly attitude</td>\n",
              "      <td>A pineapple, in a prickly personality class, s...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>A calculator crunching life's problems</td>\n",
              "      <td>A calculator, at a problem-solving workshop, c...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>A kite reaching new heights</td>\n",
              "      <td>A kite, in an altitude adjustment session, unt...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>A teddy bear feeling stuffed</td>\n",
              "      <td>A teddy bear, in a fluff mindfulness group, em...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Concept  \\\n",
              "0                 A cactus at a dance party   \n",
              "1                   A robot on a first date   \n",
              "2                A snail at a speed contest   \n",
              "3                A penguin at a beach party   \n",
              "4                     A cloud in a bad mood   \n",
              "..                                      ...   \n",
              "112      A donut feeling the hole emptiness   \n",
              "113     A pineapple with a prickly attitude   \n",
              "114  A calculator crunching life's problems   \n",
              "115             A kite reaching new heights   \n",
              "116            A teddy bear feeling stuffed   \n",
              "\n",
              "                              Funny Description Prompt  \\\n",
              "0    A cactus, wearing disco lights and surrounded ...   \n",
              "1    A robot, with a bouquet of USB cables, nervous...   \n",
              "2    A snail, with a mini rocket booster, confident...   \n",
              "3    A penguin, with sunscreen and a surfboard, try...   \n",
              "4    A cloud, grumbling and dropping mini lightning...   \n",
              "..                                                 ...   \n",
              "112  A donut, in existential bakery therapy, ponder...   \n",
              "113  A pineapple, in a prickly personality class, s...   \n",
              "114  A calculator, at a problem-solving workshop, c...   \n",
              "115  A kite, in an altitude adjustment session, unt...   \n",
              "116  A teddy bear, in a fluff mindfulness group, em...   \n",
              "\n",
              "                                                  text  \n",
              "0    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "1    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "2    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "3    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "4    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "..                                                 ...  \n",
              "112  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "113  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "114  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "115  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "116  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "\n",
              "[117 rows x 3 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"data/train.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3mr4WrwHZ0pv",
        "outputId": "6934e624-7111-4fe1-cdf2-74e0d4bff778"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'###Human:\\nGenerate a midjourney prompt for A book on a mystery adventure\\n\\n###Assistant:\\nA book, wearing detective glasses, flipping through its own pages, trying to solve the cliffhanger it was left on.'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'][15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEFbHxoPaDE_"
      },
      "source": [
        "## Step 4: Overview of AutoTrain command\n",
        "\n",
        "#### Short overview of what the command flags do.\n",
        "\n",
        "- `!autotrain`: Command executed in environments like a Jupyter notebook to run shell commands directly. `autotrain` is an automatic training utility.\n",
        "\n",
        "- `llm`: A sub-command or argument specifying the type of task\n",
        "\n",
        "- `--train`: Initiates the training process.\n",
        "\n",
        "- `--project_name`: Sets the name of the project\n",
        "\n",
        "- `--model abhishek/llama-2-7b-hf-small-shards`: Specifies original model that is hosted on Hugging Face named \"llama-2-7b-hf-small-shards\" under the \"abhishek\".\n",
        "\n",
        "- `--data_path .`: The path to the dataset for training. The \".\" refers to the current directory. The `train.csv` file needs to be located in this directory.\n",
        "\n",
        "- `--use_int4`: Use of INT4 quantization to reduce model size and speed up inference times at the cost of some precision.\n",
        "\n",
        "- `--learning_rate 2e-4`: Sets the learning rate for training to 0.0002.\n",
        "\n",
        "- `--train_batch_size 12`: Sets the batch size for training to 12.\n",
        "\n",
        "- `--num_train_epochs 3`: The training process will iterate over the dataset 3 times.\n",
        "\n",
        "### Steps needed before running\n",
        "Go to the `!autotrain` code cell below and update it by following the steps below:\n",
        "\n",
        "1. After `--project_name` replace `*enter-a-project-name*` with the name that you'd like to call the project\n",
        "2. After `--repo_id` replace `*username*/*repository*`. Replace `*username*` with your Hugging Face username and `*repository*` with the repository name you'd like it to be created under. You don't need to create this repository before hand, it will automatically be created and uploaded once the training is completed.\n",
        "3. Confirm that `train.csv` is in the root directory in the Colab. The `--data_path .` flag will make it so that AutoTrain looks for your data there.\n",
        "4. Make sure to add the LoRA Target Modules to be trained `--target-modules q_proj, v_proj`\n",
        "5. Once you've made these changes you're all set, run the command below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wFS31VJsZ-pa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[1mINFO    Running LLM\u001b[0m\n",
            "> \u001b[1mINFO    Params: Namespace(version=False, text_column='text', rejected_text_column='rejected', prompt_text_column='prompt', model_ref=None, warmup_ratio=0.1, optimizer='adamw_torch', scheduler='linear', weight_decay=0.0, max_grad_norm=1.0, add_eos_token=False, block_size=-1, peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, mixed_precision=None, quantization='int4', model_max_length=1024, trainer='sft', target_modules='q_proj,v_proj', merge_adapter=False, use_flash_attention_2=False, dpo_beta=0.1, chat_template=None, padding=None, train=True, deploy=False, inference=False, username=None, backend='local-cli', token=None, repo_id=None, push_to_hub=False, model='mistralai/Mistral-7B-Instruct-v0.2', project_name='foobar', seed=42, epochs=3, gradient_accumulation=1, disable_gradient_checkpointing=False, lr=0.0002, log='none', data_path='data', train_split='train', valid_split=None, batch_size=12, func=<function run_llm_command_factory at 0x7f4954ede050>)\u001b[0m\n",
            "> \u001b[1mINFO    Dataset: foobar (lm_training)\n",
            "Train data: ['data/train.csv']\n",
            "Valid data: []\n",
            "Column mapping: {'text': 'text', 'rejected_text': 'rejected', 'prompt': 'prompt'}\n",
            "\u001b[0m\n",
            "Saving the dataset (1/1 shards): 100%|█| 117/117 [00:00<00:00, 100231.53 example\n",
            "Saving the dataset (1/1 shards): 100%|█| 117/117 [00:00<00:00, 117823.19 example\n",
            "> \u001b[1mINFO    Starting local training...\u001b[0m\n",
            "> \u001b[1mINFO    {\"model\":\"mistralai/Mistral-7B-Instruct-v0.2\",\"project_name\":\"foobar\",\"data_path\":\"foobar/autotrain-data\",\"train_split\":\"train\",\"valid_split\":null,\"add_eos_token\":false,\"block_size\":-1,\"model_max_length\":1024,\"padding\":null,\"trainer\":\"sft\",\"use_flash_attention_2\":false,\"log\":\"none\",\"disable_gradient_checkpointing\":false,\"logging_steps\":-1,\"evaluation_strategy\":\"epoch\",\"save_total_limit\":1,\"save_strategy\":\"epoch\",\"auto_find_batch_size\":false,\"mixed_precision\":null,\"lr\":0.0002,\"epochs\":3,\"batch_size\":12,\"warmup_ratio\":0.1,\"gradient_accumulation\":1,\"optimizer\":\"adamw_torch\",\"scheduler\":\"linear\",\"weight_decay\":0.0,\"max_grad_norm\":1.0,\"seed\":42,\"chat_template\":null,\"quantization\":\"int4\",\"target_modules\":\"q_proj,v_proj\",\"merge_adapter\":false,\"peft\":true,\"lora_r\":16,\"lora_alpha\":32,\"lora_dropout\":0.05,\"model_ref\":null,\"dpo_beta\":0.1,\"prompt_text_column\":\"autotrain_prompt\",\"text_column\":\"autotrain_text\",\"rejected_text_column\":\"autotrain_rejected_text\",\"push_to_hub\":false,\"repo_id\":null,\"username\":null,\"token\":null}\u001b[0m\n",
            "> \u001b[1mINFO    ['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'foobar/training_params.json']\u001b[0m\n",
            "/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "[2024-03-14 18:32:58,678] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-03-14 18:32:58,998] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-03-14 18:32:58,998] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-03-14 18:32:58\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mloading dataset from disk\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-03-14 18:32:59\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m109\u001b[0m - \u001b[1mTrain data: Dataset({\n",
            "    features: ['Concept', 'Funny Description Prompt', 'autotrain_text'],\n",
            "    num_rows: 117\n",
            "})\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-03-14 18:32:59\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m110\u001b[0m - \u001b[1mValid data: None\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-03-14 18:32:59\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mloading model config...\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-03-14 18:33:00\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m208\u001b[0m - \u001b[1mloading model...\u001b[0m\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:05<00:00,  1.75s/it]\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-03-14 18:33:06\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m272\u001b[0m - \u001b[1mpreparing peft model...\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-03-14 18:33:06\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mUsing block size 1024\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-03-14 18:33:06\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m385\u001b[0m - \u001b[1mcreating trainer\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-03-14 18:33:06\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m398\u001b[0m - \u001b[1mLogging steps: 1\u001b[0m\n",
            "/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:815: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\n",
            "  warnings.warn(\"DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.\")\n",
            "/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:294: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "Installed CUDA version 12.3 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination\n",
            "Using /home/katopz/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /home/katopz/.cache/torch_extensions/py310_cu121/cpu_adam/build.ninja...\n",
            "Building extension module cpu_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/4] /usr/local/cuda-12.3/bin/nvcc --generate-dependencies-with-compile --dependency-output custom_cuda_kernel.cuda.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda-12.3/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/TH -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda-12.3/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ --threads=8 -gencode=arch=compute_89,code=sm_89 -gencode=arch=compute_89,code=compute_89 -DBF16_AVAILABLE -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -c /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o \n",
            "\u001b[31mFAILED: \u001b[0mcustom_cuda_kernel.cuda.o \n",
            "/usr/local/cuda-12.3/bin/nvcc --generate-dependencies-with-compile --dependency-output custom_cuda_kernel.cuda.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda-12.3/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/TH -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda-12.3/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ --threads=8 -gencode=arch=compute_89,code=sm_89 -gencode=arch=compute_89,code=compute_89 -DBF16_AVAILABLE -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -c /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o \n",
            "In file included from /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/includes/custom_cuda_layers.h:8,\n",
            "                 from /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu:6:\n",
            "/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/includes/ds_kernel_utils.h:13:10: fatal error: /usr/local/cuda-12.3/include/cuda.h: Too many levels of symbolic links\n",
            "   13 | #include <cuda.h>\n",
            "      |          ^~~~~~~~\n",
            "compilation terminated.\n",
            "In file included from /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/includes/custom_cuda_layers.h:8,\n",
            "                 from /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu:6:\n",
            "/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/includes/ds_kernel_utils.h:13:10: fatal error: /usr/local/cuda-12.3/include/cuda.h: Too many levels of symbolic links\n",
            "   13 | #include <cuda.h>\n",
            "      |          ^~~~~~~~\n",
            "compilation terminated.\n",
            "fatal   : Could not open input file /tmp/tmpxft_00004f67_00000000-7_custom_cuda_kernel.cpp1.ii\n",
            "[2/4] c++ -MMD -MF cpu_adam_impl.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda-12.3/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/TH -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda-12.3/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda-12.3/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam_impl.cpp -o cpu_adam_impl.o \n",
            "\u001b[31mFAILED: \u001b[0mcpu_adam_impl.o \n",
            "c++ -MMD -MF cpu_adam_impl.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda-12.3/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/TH -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda-12.3/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda-12.3/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam_impl.cpp -o cpu_adam_impl.o \n",
            "In file included from /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam_impl.cpp:12:\n",
            "/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/includes/cpu_adam.h:19:10: fatal error: /usr/local/cuda-12.3/include/cuda.h: Too many levels of symbolic links\n",
            "   19 | #include \"cuda.h\"\n",
            "      |          ^~~~~~~~\n",
            "compilation terminated.\n",
            "[3/4] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda-12.3/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/TH -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda-12.3/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda-12.3/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o \n",
            "\u001b[31mFAILED: \u001b[0mcpu_adam.o \n",
            "c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda-12.3/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/TH -isystem /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda-12.3/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda-12.3/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o \n",
            "In file included from /home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp:6:\n",
            "/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/csrc/includes/cpu_adam.h:19:10: fatal error: /usr/local/cuda-12.3/include/cuda.h: Too many levels of symbolic links\n",
            "   19 | #include \"cuda.h\"\n",
            "      |          ^~~~~~~~\n",
            "compilation terminated.\n",
            "ninja: build stopped: subcommand failed.\n",
            "\u001b[31m\u001b[1m❌ ERROR \u001b[0m | \u001b[32m2024-03-14 18:33:11\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m93\u001b[0m - \u001b[31m\u001b[1mtrain has failed due to an exception: Traceback (most recent call last):\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 2096, in _run_ninja_build\n",
            "    subprocess.run(\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 526, in run\n",
            "    raise CalledProcessError(retcode, process.args,\n",
            "subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/autotrain/trainers/common.py\", line 90, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/autotrain/trainers/clm/__main__.py\", line 523, in train\n",
            "    trainer.train()\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py\", line 331, in train\n",
            "    output = super().train(*args, **kwargs)\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/transformers/trainer.py\", line 1624, in train\n",
            "    return inner_training_loop(\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/transformers/trainer.py\", line 1776, in _inner_training_loop\n",
            "    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1255, in prepare\n",
            "    result = self._prepare_deepspeed(*args)\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1634, in _prepare_deepspeed\n",
            "    optimizer = DeepSpeedCPUAdam(optimizer.param_groups, **defaults)\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/adam/cpu_adam.py\", line 94, in __init__\n",
            "    self.ds_opt_adam = CPUAdamBuilder().load()\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py\", line 479, in load\n",
            "    return self.jit_load(verbose)\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py\", line 523, in jit_load\n",
            "    op_module = load(name=self.name,\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1306, in load\n",
            "    return _jit_compile(\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1710, in _jit_compile\n",
            "    _write_ninja_file_and_build_library(\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1823, in _write_ninja_file_and_build_library\n",
            "    _run_ninja_build(\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 2112, in _run_ninja_build\n",
            "    raise RuntimeError(message) from e\n",
            "RuntimeError: Error building extension 'cpu_adam'\n",
            "\u001b[0m\n",
            "\u001b[31m\u001b[1m❌ ERROR \u001b[0m | \u001b[32m2024-03-14 18:33:11\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m94\u001b[0m - \u001b[31m\u001b[1mError building extension 'cpu_adam'\u001b[0m\n",
            "Exception ignored in: <function DeepSpeedCPUAdam.__del__ at 0x7f2781d9be20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/katopz/book/src/ml/finetuning/sft/.venv/lib/python3.10/site-packages/deepspeed/ops/adam/cpu_adam.py\", line 102, in __del__\n",
            "    self.ds_opt_adam.destroy_adam(self.opt_id)\n",
            "AttributeError: 'DeepSpeedCPUAdam' object has no attribute 'ds_opt_adam'\n"
          ]
        }
      ],
      "source": [
        "!autotrain llm --train \\\n",
        "    --project-name foobar \\\n",
        "    --model mistralai/Mistral-7B-Instruct-v0.2 \\\n",
        "    --data-path data \\\n",
        "    --lr 2e-4 \\\n",
        "    --batch-size 12 \\\n",
        "    --epochs 3 \\\n",
        "    --trainer sft \\\n",
        "    --target-modules q_proj,v_proj \\\n",
        "    --quantization int4 \\\n",
        "    --peft \\\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEf6G0iPc0Nr"
      },
      "source": [
        "## Step 5: Completed 🎉\n",
        "After the command above is completed your Model will be uploaded to Hugging Face.\n",
        "\n",
        "#### Learn more about AutoTrain (optional)\n",
        "If you want to learn more about what command-line flags are available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIoxuAEAfJ4z"
      },
      "source": [
        "## Step 6: Inference Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aYsYyXmrc0xu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: autotrain <command> [<args>] llm [-h] [--text_column TEXT_COLUMN]\n",
            "                                        [--rejected_text_column REJECTED_TEXT_COLUMN]\n",
            "                                        [--prompt-text-column PROMPT_TEXT_COLUMN]\n",
            "                                        [--model-ref MODEL_REF]\n",
            "                                        [--warmup_ratio WARMUP_RATIO]\n",
            "                                        [--optimizer OPTIMIZER]\n",
            "                                        [--scheduler SCHEDULER]\n",
            "                                        [--weight_decay WEIGHT_DECAY]\n",
            "                                        [--max_grad_norm MAX_GRAD_NORM]\n",
            "                                        [--add_eos_token]\n",
            "                                        [--block_size BLOCK_SIZE] [--peft]\n",
            "                                        [--lora_r LORA_R]\n",
            "                                        [--lora_alpha LORA_ALPHA]\n",
            "                                        [--lora_dropout LORA_DROPOUT]\n",
            "                                        [--logging_steps LOGGING_STEPS]\n",
            "                                        [--evaluation_strategy EVALUATION_STRATEGY]\n",
            "                                        [--save_total_limit SAVE_TOTAL_LIMIT]\n",
            "                                        [--save_strategy SAVE_STRATEGY]\n",
            "                                        [--auto_find_batch_size]\n",
            "                                        [--mixed-precision MIXED_PRECISION]\n",
            "                                        [--quantization QUANTIZATION]\n",
            "                                        [--model_max_length MODEL_MAX_LENGTH]\n",
            "                                        [--trainer TRAINER]\n",
            "                                        [--target_modules TARGET_MODULES]\n",
            "                                        [--merge_adapter]\n",
            "                                        [--use_flash_attention_2]\n",
            "                                        [--dpo-beta DPO_BETA]\n",
            "                                        [--chat_template CHAT_TEMPLATE]\n",
            "                                        [--padding PADDING] [--train]\n",
            "                                        [--deploy] [--inference]\n",
            "                                        [--username USERNAME]\n",
            "                                        [--backend BACKEND] [--token TOKEN]\n",
            "                                        [--repo-id REPO_ID] [--push-to-hub]\n",
            "                                        --model MODEL --project-name\n",
            "                                        PROJECT_NAME [--seed SEED]\n",
            "                                        [--epochs EPOCHS]\n",
            "                                        [--gradient-accumulation GRADIENT_ACCUMULATION]\n",
            "                                        [--disable_gradient_checkpointing]\n",
            "                                        [--lr LR] [--log LOG]\n",
            "                                        [--data-path DATA_PATH]\n",
            "                                        [--train-split TRAIN_SPLIT]\n",
            "                                        [--valid-split VALID_SPLIT]\n",
            "                                        [--batch-size BATCH_SIZE]\n",
            "\n",
            "✨ Run AutoTrain LLM\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --text_column TEXT_COLUMN, --text-column TEXT_COLUMN\n",
            "                        Text column to use\n",
            "  --rejected_text_column REJECTED_TEXT_COLUMN, --rejected-text-column REJECTED_TEXT_COLUMN\n",
            "                        Rejected text column to use\n",
            "  --prompt-text-column PROMPT_TEXT_COLUMN, --prompt-text-column PROMPT_TEXT_COLUMN\n",
            "                        Prompt text column to use\n",
            "  --model-ref MODEL_REF\n",
            "                        Reference model to use for DPO when not using PEFT\n",
            "  --warmup_ratio WARMUP_RATIO, --warmup-ratio WARMUP_RATIO\n",
            "                        Warmup proportion to use\n",
            "  --optimizer OPTIMIZER\n",
            "                        Optimizer to use\n",
            "  --scheduler SCHEDULER\n",
            "                        Scheduler to use\n",
            "  --weight_decay WEIGHT_DECAY, --weight-decay WEIGHT_DECAY\n",
            "                        Weight decay to use\n",
            "  --max_grad_norm MAX_GRAD_NORM, --max-grad-norm MAX_GRAD_NORM\n",
            "                        Max gradient norm to use\n",
            "  --add_eos_token, --add-eos-token\n",
            "                        Add EOS token to use\n",
            "  --block_size BLOCK_SIZE, --block-size BLOCK_SIZE\n",
            "                        Block size to use\n",
            "  --peft, --use-peft    Use PEFT\n",
            "  --lora_r LORA_R, --lora-r LORA_R\n",
            "                        Lora r to use\n",
            "  --lora_alpha LORA_ALPHA, --lora-alpha LORA_ALPHA\n",
            "                        Lora alpha to use\n",
            "  --lora_dropout LORA_DROPOUT, --lora-dropout LORA_DROPOUT\n",
            "                        Lora dropout to use\n",
            "  --logging_steps LOGGING_STEPS, --logging-steps LOGGING_STEPS\n",
            "                        Logging steps to use\n",
            "  --evaluation_strategy EVALUATION_STRATEGY, --evaluation-strategy EVALUATION_STRATEGY\n",
            "                        Evaluation strategy to use\n",
            "  --save_total_limit SAVE_TOTAL_LIMIT, --save-total-limit SAVE_TOTAL_LIMIT\n",
            "                        Save total limit to use\n",
            "  --save_strategy SAVE_STRATEGY, --save-strategy SAVE_STRATEGY\n",
            "                        Save strategy to use\n",
            "  --auto_find_batch_size, --auto-find-batch-size\n",
            "                        Auto find batch size True/False\n",
            "  --mixed-precision MIXED_PRECISION, --mixed-precision MIXED_PRECISION, --mp MIXED_PRECISION\n",
            "                        fp16, bf16, or None\n",
            "  --quantization QUANTIZATION, --quantization QUANTIZATION\n",
            "                        int4, int8, or None\n",
            "  --model_max_length MODEL_MAX_LENGTH, --max-len MODEL_MAX_LENGTH, --max-length MODEL_MAX_LENGTH\n",
            "                        Model max length to use\n",
            "  --trainer TRAINER     Trainer type to use\n",
            "  --target_modules TARGET_MODULES, --target-modules TARGET_MODULES\n",
            "                        Target modules to use\n",
            "  --merge_adapter, --merge-adapter\n",
            "                        Use this flag to merge PEFT adapter with the model\n",
            "  --use_flash_attention_2, --use-flash-attention-2, --use-fa2\n",
            "                        Use flash attention 2\n",
            "  --dpo-beta DPO_BETA, --dpo-beta DPO_BETA\n",
            "                        Beta for DPO trainer\n",
            "  --chat_template CHAT_TEMPLATE, --chat-template CHAT_TEMPLATE\n",
            "                        Apply chat template\n",
            "  --padding PADDING, --padding PADDING\n",
            "                        Padding side\n",
            "  --train               Train the model\n",
            "  --deploy              Deploy the model\n",
            "  --inference           Run inference\n",
            "  --username USERNAME   Hugging Face Hub Username\n",
            "  --backend BACKEND     Backend to use: default or spaces. Spaces backend\n",
            "                        requires push_to_hub and repo_id\n",
            "  --token TOKEN         Hub token\n",
            "  --repo-id REPO_ID     Hub repo id\n",
            "  --push-to-hub         Push to hub\n",
            "  --model MODEL         Model to use for training\n",
            "  --project-name PROJECT_NAME\n",
            "                        Output directory or repo id\n",
            "  --seed SEED           Seed\n",
            "  --epochs EPOCHS       Number of training epochs\n",
            "  --gradient-accumulation GRADIENT_ACCUMULATION\n",
            "                        Gradient accumulation steps\n",
            "  --disable_gradient_checkpointing, --disable-gradient-checkpointing, --disable-gc\n",
            "                        Disable gradient checkpointing\n",
            "  --lr LR               Learning rate\n",
            "  --log LOG             Use experiment tracking\n",
            "  --data-path DATA_PATH\n",
            "                        Train dataset to use\n",
            "  --train-split TRAIN_SPLIT\n",
            "                        Test dataset split to use\n",
            "  --valid-split VALID_SPLIT\n",
            "                        Validation dataset split to use\n",
            "  --batch-size BATCH_SIZE, --train-batch-size BATCH_SIZE\n",
            "                        Training batch size to use\n"
          ]
        }
      ],
      "source": [
        "!autotrain llm -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5m1ouhWhc2fr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q peft  accelerate bitsandbytes safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s-nDnnPc--U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import transformers\n",
        "adapters_name = \"ashishpatel26/mistral-7b-mj-finetuned\"\n",
        "model_name = \"bn22/Mistral-7B-Instruct-v0.1-sharded\" #\"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "\n",
        "device = \"cuda\" # the device to load the model onto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HosPywN_dEpl"
      },
      "outputs": [],
      "source": [
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fcb820b4909e413e98603c195818e0d4",
            "6b0a6739adbe41e8a5c34f8a8868b977",
            "0b9514defba84991b4f36485b7e630fb",
            "6a7973751e4d4ca08ef4c53c97103868",
            "0deb9610aaff49c488b6e89139fe31df",
            "89f149a2080f4721a483ff535b6e6602",
            "4f62c475347944d6b18ce79d125386fc",
            "996db8f083904106913a3e4b4d6627c9",
            "f6b2ea40822a41899aae6768c5a34c73",
            "4523834103534e2b9fb804bdb5265a1e",
            "3912010e0694457f9f777c1bbb996967"
          ]
        },
        "id": "GtZx4CZUdt1f",
        "outputId": "c01df71d-a70e-48d3-d651-0061856f1b57"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcb820b4909e413e98603c195818e0d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_4bit=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh5Xc0clfQkZ"
      },
      "source": [
        "## Step 7: Peft Model Loading with upload model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rt6sOPFVdvWX"
      },
      "outputs": [],
      "source": [
        "model = PeftModel.from_pretrained(model, adapters_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3OArVILeoZH",
        "outputId": "af68bc96-c9a8-4801-f8d6-5f2095101988"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded the model bn22/Mistral-7B-Instruct-v0.1-sharded into memory\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.bos_token_id = 1\n",
        "\n",
        "stop_token_ids = [0]\n",
        "\n",
        "print(f\"Successfully loaded the model {model_name} into memory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbOOX8cve0lR",
        "outputId": "3052b329-7bf5-4bb4-bec5-b71e881bbc21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1539: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INST] generate a midjourney prompt for A person walks in the rain [/INST] \"As you wander through the pouring rain, you can't help but wonder what the world would be like if things were different. What if the rain was a symbol of the turmoil in your life, and the sunshine promised a brighter future? What if you suddenly found yourself lost in a small town where time stood still, and the people were trapped in a time loop? As you struggle to find your way back to reality, you discover a mysterious stranger who seems to hold the key to unlocking the secrets of the town and your own past.\"</s>\n"
          ]
        }
      ],
      "source": [
        "text = \"[INST] generate a midjourney prompt for A person walks in the rain [/INST]\"\n",
        "\n",
        "encoded = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
        "model_input = encoded\n",
        "model.to(device)\n",
        "generated_ids = model.generate(**model_input, max_new_tokens=200, do_sample=True)\n",
        "decoded = tokenizer.batch_decode(generated_ids)\n",
        "print(decoded[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0394a80f33694ddcaac86d11eb55dfba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07a86a9d6045490582005ae3dc6235b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b9514defba84991b4f36485b7e630fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_996db8f083904106913a3e4b4d6627c9",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6b2ea40822a41899aae6768c5a34c73",
            "value": 11
          }
        },
        "0deb9610aaff49c488b6e89139fe31df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13f4a118e7ef4a148bde03a6e84e8aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1878c66b2eae453a864ffead4070b1b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07a86a9d6045490582005ae3dc6235b4",
            "placeholder": "​",
            "style": "IPY_MODEL_26203a05198d4ceeacbf5e773709f351",
            "value": "Connecting..."
          }
        },
        "1b54ffd23ba74eeebd9c469f440fb681": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ea83882b0c24fc6bdc55ec477e8d966",
            "placeholder": "​",
            "style": "IPY_MODEL_9cee18be45e147d094a9f3d563e43deb",
            "value": "Token is valid (permission: write)."
          }
        },
        "2087238355ef44719f296fa797fdd1a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "229eb3fe560b47cfaf90bd897d0356a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "2488b59a84c4450a87d03d1a7416131a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26203a05198d4ceeacbf5e773709f351": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32368ce026824d4faad5f96bb523b1ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361f03f842874570ba0f5a7992ef85bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_2087238355ef44719f296fa797fdd1a4",
            "style": "IPY_MODEL_3a25c5df13944295882f0114971dad95",
            "tooltip": ""
          }
        },
        "3912010e0694457f9f777c1bbb996967": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a25c5df13944295882f0114971dad95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3be1673dc1ce401f9bf74665671fe25e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c4c437c3be348a6beaa549a070e7d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2488b59a84c4450a87d03d1a7416131a",
            "placeholder": "​",
            "style": "IPY_MODEL_aba01680bd644852bdd01943fe6ff3a8",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "3e3a59c9cd1e4bab9a7134b3ed460a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ea83882b0c24fc6bdc55ec477e8d966": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4523834103534e2b9fb804bdb5265a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f62c475347944d6b18ce79d125386fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a7973751e4d4ca08ef4c53c97103868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4523834103534e2b9fb804bdb5265a1e",
            "placeholder": "​",
            "style": "IPY_MODEL_3912010e0694457f9f777c1bbb996967",
            "value": " 11/11 [01:22&lt;00:00,  5.56s/it]"
          }
        },
        "6b08ab9f42604d50b75ca79953cdb513": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7a697bfe78e4ef3ba7c086c6a7dc9a0",
            "placeholder": "​",
            "style": "IPY_MODEL_3e3a59c9cd1e4bab9a7134b3ed460a70",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "6b0a6739adbe41e8a5c34f8a8868b977": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89f149a2080f4721a483ff535b6e6602",
            "placeholder": "​",
            "style": "IPY_MODEL_4f62c475347944d6b18ce79d125386fc",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6c9bfecb5c7d4218b905c5d9d1a94e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89f149a2080f4721a483ff535b6e6602": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93721b72963843db8afd2dc95b1a7e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b54ffd23ba74eeebd9c469f440fb681",
              "IPY_MODEL_6b08ab9f42604d50b75ca79953cdb513",
              "IPY_MODEL_da126394b0454dfa92ead879aa4d05f8",
              "IPY_MODEL_cdad03b3eb6f4b8498d4c095ef4bd77c"
            ],
            "layout": "IPY_MODEL_229eb3fe560b47cfaf90bd897d0356a3"
          }
        },
        "996db8f083904106913a3e4b4d6627c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c9e13827ccd49c28eb7e4b5b7bce367": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cee18be45e147d094a9f3d563e43deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aba01680bd644852bdd01943fe6ff3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bef331d1317e4dca8423b41d9a4d5a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_32368ce026824d4faad5f96bb523b1ef",
            "placeholder": "​",
            "style": "IPY_MODEL_6c9bfecb5c7d4218b905c5d9d1a94e67",
            "value": ""
          }
        },
        "c7a697bfe78e4ef3ba7c086c6a7dc9a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdad03b3eb6f4b8498d4c095ef4bd77c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e72159dd38c04fda9b6944b21ef7ee18",
            "placeholder": "​",
            "style": "IPY_MODEL_3be1673dc1ce401f9bf74665671fe25e",
            "value": "Login successful"
          }
        },
        "cdcf8ddbe33d443ebb8e746da30ac0e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d65e536585574e1ebbe7dc596e5fff5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da126394b0454dfa92ead879aa4d05f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13f4a118e7ef4a148bde03a6e84e8aa3",
            "placeholder": "​",
            "style": "IPY_MODEL_da203394bbcb4a3a98ccf00c99c8397c",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "da203394bbcb4a3a98ccf00c99c8397c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da5b0da670514701962d1fb278d2c806": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c9e13827ccd49c28eb7e4b5b7bce367",
            "placeholder": "​",
            "style": "IPY_MODEL_d65e536585574e1ebbe7dc596e5fff5b",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "e72159dd38c04fda9b6944b21ef7ee18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6b2ea40822a41899aae6768c5a34c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcb820b4909e413e98603c195818e0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b0a6739adbe41e8a5c34f8a8868b977",
              "IPY_MODEL_0b9514defba84991b4f36485b7e630fb",
              "IPY_MODEL_6a7973751e4d4ca08ef4c53c97103868"
            ],
            "layout": "IPY_MODEL_0deb9610aaff49c488b6e89139fe31df"
          }
        },
        "fd8eb83e711f4efeb5392159094979ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_cdcf8ddbe33d443ebb8e746da30ac0e7",
            "style": "IPY_MODEL_0394a80f33694ddcaac86d11eb55dfba",
            "value": true
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
