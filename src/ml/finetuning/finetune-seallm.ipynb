{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f76265",
   "metadata": {
    "papermill": {
     "duration": 0.01382,
     "end_time": "2023-12-14T06:20:59.424944",
     "exception": false,
     "start_time": "2023-12-14T06:20:59.411124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-tuning LLM on Your Own Dataset with QLoRA on a Single GPU\n",
    "\n",
    "Fine-tune the LLM base model on a custom dataset. We'll use the QLoRa technique to train an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3be3533",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:20:59.452704Z",
     "iopub.status.busy": "2023-12-14T06:20:59.452131Z",
     "iopub.status.idle": "2023-12-14T06:21:00.439239Z",
     "shell.execute_reply": "2023-12-14T06:21:00.438154Z"
    },
    "papermill": {
     "duration": 1.003781,
     "end_time": "2023-12-14T06:21:00.441780",
     "exception": false,
     "start_time": "2023-12-14T06:20:59.437999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 15 21:44:28 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 546.01       CUDA Version: 12.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  Off |\n",
      "|  0%   41C    P8    25W / 450W |    968MiB / 24564MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387e49b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv .venv\n",
    "!source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe9ca3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qqq fastembed==\"0.2.1\" --progress-bar off\n",
    "!pip install -qqq tokenizers==\"0.15.2\" --progress-bar off\n",
    "!pip install -qqq loguru==\"0.7.2\" --progress-bar off\n",
    "!pip install -qqq tqdm==\"4.66.0\" --progress-bar off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7cf4baf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:21:00.469842Z",
     "iopub.status.busy": "2023-12-14T06:21:00.469529Z",
     "iopub.status.idle": "2023-12-14T06:22:11.140453Z",
     "shell.execute_reply": "2023-12-14T06:22:11.139188Z"
    },
    "papermill": {
     "duration": 70.687848,
     "end_time": "2023-12-14T06:22:11.143164",
     "exception": false,
     "start_time": "2023-12-14T06:21:00.455316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install ipywidgets\n",
    "!pip install -qqq torch --progress-bar off\n",
    "!pip install -qqq transformers==4.37.0 --progress-bar off\n",
    "!pip install -qqq datasets==2.14.4 --progress-bar off\n",
    "!pip install -qqq peft==0.8.2 --progress-bar off\n",
    "!pip install -qqq bitsandbytes==0.42.0 --progress-bar off\n",
    "!pip install -qqq trl==0.7.4 --progress-bar off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae23e679",
   "metadata": {
    "papermill": {
     "duration": 0.015811,
     "end_time": "2023-12-14T06:22:11.173141",
     "exception": false,
     "start_time": "2023-12-14T06:22:11.157330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba51f09",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2023-12-14T06:22:11.187108",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-15 21:44:48,135] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katopz/.local/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from huggingface_hub import login\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint\n",
    "from trl import SFTTrainer\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    AutoPeftModelForCausalLM\n",
    ")\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ff2e0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:06:29.578866Z",
     "iopub.status.busy": "2023-12-14T04:06:29.578356Z",
     "iopub.status.idle": "2023-12-14T04:06:29.584058Z",
     "shell.execute_reply": "2023-12-14T04:06:29.583205Z",
     "shell.execute_reply.started": "2023-12-14T04:06:29.578840Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"using {DEVICE} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "268f3685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:06:29.586502Z",
     "iopub.status.busy": "2023-12-14T04:06:29.586097Z",
     "iopub.status.idle": "2023-12-14T04:06:29.600711Z",
     "shell.execute_reply": "2023-12-14T04:06:29.600031Z",
     "shell.execute_reply.started": "2023-12-14T04:06:29.586463Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training prompt for instruction finetuning using '###' format\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\" คุณเป็นนักเรียนที่คอยตอบคำถาม โดยข้างล่างต่อไปนี้คือคำถาม จงตอบคำถามต่อไปนี้ \"\"\"\n",
    "\n",
    "\n",
    "###------------------------------ Process Dataset ------------------------------###\n",
    "def generate_training_prompt(\n",
    "    question: str, answer: str,\n",
    "    system_prompt: str = DEFAULT_SYSTEM_PROMPT\n",
    ") -> str:\n",
    "    return f\"\"\"### คำสั่ง:\n",
    "{system_prompt.strip()}\n",
    "\n",
    "### คำถาม:\n",
    "{question.strip()}\n",
    "\n",
    "### คำตอบ:\n",
    "{answer.strip()}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def process_dataset(data: pd.DataFrame):\n",
    "    data[\"text\"] = data.apply(\n",
    "        lambda row: generate_training_prompt(\n",
    "            row[\"question\"], row[\"answer\"]\n",
    "        ), axis=1\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a18d0de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:06:29.601814Z",
     "iopub.status.busy": "2023-12-14T04:06:29.601553Z",
     "iopub.status.idle": "2023-12-14T04:06:29.635672Z",
     "shell.execute_reply": "2023-12-14T04:06:29.634644Z",
     "shell.execute_reply.started": "2023-12-14T04:06:29.601791Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/katopz/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(token=\"YOUR_HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af658489",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Loading the model\n",
    "\n",
    "Define the [Lora Config](https://huggingface.co/docs/peft/main/en/package_reference/tuners#peft.LoraConfig) with:\n",
    "\n",
    "- `task_type`, token classification **(TaskType.TOKEN_CLS)**\n",
    "- `r`, the dimension of the low-rank matrices\n",
    "- `lora_alpha`, scaling factor for the weight matrices\n",
    "- `lora_dropout`, dropout probability of the LoRA layers\n",
    "- `bias`, set to **all** to train all bias parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "941862c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:06:40.822300Z",
     "iopub.status.busy": "2023-12-14T04:06:40.821908Z",
     "iopub.status.idle": "2023-12-14T04:06:40.830192Z",
     "shell.execute_reply": "2023-12-14T04:06:40.829209Z",
     "shell.execute_reply.started": "2023-12-14T04:06:40.822271Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"SeaLLMs/SeaLLM-7B-v2\"  # @param [\"pythainlp/wangchanglm-7.5B-sft-enth-sharded\", \"TinyPixel/Llama-2-7B-bf16-sharded\", \"SeaLLMs/SeaLLM-7B-Chat\"]\n",
    "\n",
    "# Load both LLM model and tokenizer\n",
    "def load_LLM_and_tokenizer():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    if \"wangchanglm\" in model_id:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            return_dict=True,\n",
    "            load_in_8bit=True,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "            quantization_config=bnb_config,\n",
    "        )\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"facebook/xglm-7.5B\")\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            quantization_config=bnb_config,\n",
    "            trust_remote_code=True,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.add_special_tokens = False\n",
    "        tokenizer.padding_side = \"right\"\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1032cf47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:06:43.951397Z",
     "iopub.status.busy": "2023-12-14T04:06:43.950763Z",
     "iopub.status.idle": "2023-12-14T04:10:13.930476Z",
     "shell.execute_reply": "2023-12-14T04:10:13.929386Z",
     "shell.execute_reply.started": "2023-12-14T04:06:43.951366Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa40abc130048ccb659900bc7c2462b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/632 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4906da91ea64d3486d58209eb34f61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/14.8G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b478d2104d242b3a4efa339850bde41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98ba531849c40eba5838240761dcf1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/780k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed58bff17d6b4aeeb4404f8ca4d91848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f458c62577c6405db198e7928dfe0a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = load_LLM_and_tokenizer()\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b1fbdb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Dataset Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ea09619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:19:59.007736Z",
     "iopub.status.busy": "2023-12-14T04:19:59.007346Z",
     "iopub.status.idle": "2023-12-14T04:19:59.069678Z",
     "shell.execute_reply": "2023-12-14T04:19:59.068734Z",
     "shell.execute_reply.started": "2023-12-14T04:19:59.007695Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sysid</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>640696</td>\n",
       "      <td>ชื่ออะไร</td>\n",
       "      <td>ชื่อต๊อบ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>640696</td>\n",
       "      <td>ต๊อบชอบกินอะไร</td>\n",
       "      <td>ถั่ว</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>640696</td>\n",
       "      <td>ต๊อบชอบไปไหน</td>\n",
       "      <td>ไปเที่ยว</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>320422</td>\n",
       "      <td>ต๊อบชอบสีอะไร</td>\n",
       "      <td>เทา</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320422</td>\n",
       "      <td>ต๊อบสูงเท่าไหร่</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sysid         question    answer\n",
       "0  640696         ชื่ออะไร  ชื่อต๊อบ\n",
       "1  640696   ต๊อบชอบกินอะไร      ถั่ว\n",
       "2  640696     ต๊อบชอบไปไหน  ไปเที่ยว\n",
       "3  320422    ต๊อบชอบสีอะไร       เทา\n",
       "4  320422  ต๊อบสูงเท่าไหร่       173"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "law_dataset = pd.read_csv(\"./test.csv\")\n",
    "law_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7421502b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:20:01.613820Z",
     "iopub.status.busy": "2023-12-14T04:20:01.613415Z",
     "iopub.status.idle": "2023-12-14T04:20:01.620163Z",
     "shell.execute_reply": "2023-12-14T04:20:01.619144Z",
     "shell.execute_reply.started": "2023-12-14T04:20:01.613787Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "law_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a04dfbe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:20:03.193936Z",
     "iopub.status.busy": "2023-12-14T04:20:03.193288Z",
     "iopub.status.idle": "2023-12-14T04:20:03.200126Z",
     "shell.execute_reply": "2023-12-14T04:20:03.199251Z",
     "shell.execute_reply.started": "2023-12-14T04:20:03.193903Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: limit first 1000 rows for lower resource\n",
    "law_dataset = law_dataset[:100]\n",
    "law_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2d0c74c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:20:04.976844Z",
     "iopub.status.busy": "2023-12-14T04:20:04.976473Z",
     "iopub.status.idle": "2023-12-14T04:20:04.987645Z",
     "shell.execute_reply": "2023-12-14T04:20:04.986735Z",
     "shell.execute_reply.started": "2023-12-14T04:20:04.976813Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (79, 3)\n",
      "Validation set shape: (10, 3)\n",
      "Test set shape: (10, 3)\n"
     ]
    }
   ],
   "source": [
    "# Specify the proportions for train, validation, and test sets\n",
    "train_ratio = 0.8\n",
    "validation_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Split the dataset\n",
    "train_data, temp_data = train_test_split(law_dataset, test_size=1 - train_ratio, random_state=42)\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting DataFrames\n",
    "print(\"Train set shape:\", train_data.shape)\n",
    "print(\"Validation set shape:\", validation_data.shape)\n",
    "print(\"Test set shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "926ac7b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:20:07.054983Z",
     "iopub.status.busy": "2023-12-14T04:20:07.054593Z",
     "iopub.status.idle": "2023-12-14T04:20:07.077465Z",
     "shell.execute_reply": "2023-12-14T04:20:07.076543Z",
     "shell.execute_reply.started": "2023-12-14T04:20:07.054952Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = process_dataset(train_data)\n",
    "validation_data = process_dataset(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59337dd1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "validation_dataset = Dataset.from_pandas(validation_data)\n",
    "\n",
    "combine_dataset = DatasetDict()\n",
    "combine_dataset['train'] = train_dataset\n",
    "combine_dataset['validation'] = validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17cbe176",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:20:10.549875Z",
     "iopub.status.busy": "2023-12-14T04:20:10.548994Z",
     "iopub.status.idle": "2023-12-14T04:20:10.555605Z",
     "shell.execute_reply": "2023-12-14T04:20:10.554623Z",
     "shell.execute_reply.started": "2023-12-14T04:20:10.549842Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sysid', 'question', 'answer', 'text', '__index_level_0__'],\n",
       "        num_rows: 79\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sysid', 'question', 'answer', 'text', '__index_level_0__'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c0d30",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Inference with Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7295a865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ต๊อบชอบไปไหน</td>\n",
       "      <td>ไปเที่ยว</td>\n",
       "      <td>### คำสั่ง:\\nข้างล่างต่อไปนี้คือคำถาม จงตอบคำถ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ต๊อบชอบไปไหน</td>\n",
       "      <td>ไปเที่ยว</td>\n",
       "      <td>### คำสั่ง:\\nข้างล่างต่อไปนี้คือคำถาม จงตอบคำถ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ต๊อบสูงเท่าไหร่</td>\n",
       "      <td>173</td>\n",
       "      <td>### คำสั่ง:\\nข้างล่างต่อไปนี้คือคำถาม จงตอบคำถ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ชื่ออะไร</td>\n",
       "      <td>ชื่อต๊อบ</td>\n",
       "      <td>### คำสั่ง:\\nข้างล่างต่อไปนี้คือคำถาม จงตอบคำถ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ชื่ออะไร</td>\n",
       "      <td>ชื่อต๊อบ</td>\n",
       "      <td>### คำสั่ง:\\nข้างล่างต่อไปนี้คือคำถาม จงตอบคำถ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          question  response  \\\n",
       "0     ต๊อบชอบไปไหน  ไปเที่ยว   \n",
       "1     ต๊อบชอบไปไหน  ไปเที่ยว   \n",
       "2  ต๊อบสูงเท่าไหร่       173   \n",
       "3         ชื่ออะไร  ชื่อต๊อบ   \n",
       "4         ชื่ออะไร  ชื่อต๊อบ   \n",
       "\n",
       "                                                text  \n",
       "0  ### คำสั่ง:\\nข้างล่างต่อไปนี้คือคำถาม จงตอบคำถ...  \n",
       "1  ### คำสั่ง:\\nข้างล่างต่อไปนี้คือคำถาม จงตอบคำถ...  \n",
       "2  ### คำสั่ง:\\nข้างล่างต่อไปนี้คือคำถาม จงตอบคำถ...  \n",
       "3  ### คำสั่ง:\\nข้างล่างต่อไปนี้คือคำถาม จงตอบคำถ...  \n",
       "4  ### คำสั่ง:\\nข้างล่างต่อไปนี้คือคำถาม จงตอบคำถ...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INFERENCE_SYSTEM_PROMPT = \"\"\" ข้างล่างต่อไปนี้คือคำถาม จงตอบคำถามต่อไปนี้ \"\"\"\n",
    "\n",
    "max_new_tokens = 256    # @param {type: \"integer\"}\n",
    "temperature = 0.0001    # @param {type: \"number\"}\n",
    "\n",
    "def generate_answer(model, text: str):\n",
    "    batch = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        output_tokens = model.generate(\n",
    "            input_ids=batch[\"input_ids\"].to(DEVICE),\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            no_repeat_ngram_size=2,\n",
    "            typical_p=1.,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    return tokenizer.decode(output_tokens[0][len(batch[\"input_ids\"][0]):], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def generate_inference_prompt(\n",
    "    question: str,\n",
    "    system_prompt: str = INFERENCE_SYSTEM_PROMPT\n",
    ") -> str:\n",
    "    return f\"\"\"### คำสั่ง:\n",
    "{system_prompt.strip()}\n",
    "\n",
    "### คำถาม:\n",
    "{question.strip()}\n",
    "\n",
    "### คำตอบ:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "examples = []\n",
    "for index, data_point in test_data.head(5).iterrows():\n",
    "    question = data_point[\"question\"]\n",
    "    label = data_point[\"answer\"]\n",
    "    examples.append({\n",
    "        \"question\": question,\n",
    "        \"response\": label,\n",
    "        \"text\": generate_inference_prompt(question)\n",
    "    })\n",
    "\n",
    "test_df = pd.DataFrame(examples)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6710a3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "643a6ed3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:20:15.311619Z",
     "iopub.status.busy": "2023-12-14T04:20:15.311232Z",
     "iopub.status.idle": "2023-12-14T04:20:15.317328Z",
     "shell.execute_reply": "2023-12-14T04:20:15.316235Z",
     "shell.execute_reply.started": "2023-12-14T04:20:15.311571Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ชื่ออะไร\n"
     ]
    }
   ],
   "source": [
    "example = test_df.iloc[3]\n",
    "print(example.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "57d27263",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 214 ms, sys: 169 ms, total: 383 ms\n",
      "Wall time: 377 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = generate_answer(model, example.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f13a048b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T09:16:28.363573Z",
     "iopub.status.busy": "2023-12-13T09:16:28.362848Z",
     "iopub.status.idle": "2023-12-13T09:16:28.368423Z",
     "shell.execute_reply": "2023-12-13T09:16:28.367406Z",
     "shell.execute_reply.started": "2023-12-13T09:16:28.363543Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n"
     ]
    }
   ],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0a34025f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T09:16:28.369980Z",
     "iopub.status.busy": "2023-12-13T09:16:28.369648Z",
     "iopub.status.idle": "2023-12-13T09:16:28.382742Z",
     "shell.execute_reply": "2023-12-13T09:16:28.381822Z",
     "shell.execute_reply.started": "2023-12-13T09:16:28.369941Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ชื่อต๊อบ'\n"
     ]
    }
   ],
   "source": [
    "pprint(example.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f2339",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Finetune QLoRA\n",
    "\n",
    "Here we will use the `SFTTrainer` from [TRL library](https://huggingface.co/docs/trl/main/en/sft_trainer) that gives a wrapper around transformers `Trainer` to easily fine-tune models on instruction based datasets using PEFT adapters. Let's first load the training arguments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "352773e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T09:17:11.591227Z",
     "iopub.status.busy": "2023-12-13T09:17:11.590836Z",
     "iopub.status.idle": "2023-12-13T09:17:11.601958Z",
     "shell.execute_reply": "2023-12-13T09:17:11.600830Z",
     "shell.execute_reply.started": "2023-12-13T09:17:11.591197Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(48384, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm()\n",
       "            (post_attention_layernorm): MistralRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=48384, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42ac5494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T09:17:13.788741Z",
     "iopub.status.busy": "2023-12-13T09:17:13.787913Z",
     "iopub.status.idle": "2023-12-13T09:17:13.795308Z",
     "shell.execute_reply": "2023-12-13T09:17:13.794264Z",
     "shell.execute_reply.started": "2023-12-13T09:17:13.788709Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_method': <QuantizationMethod.BITS_AND_BYTES: 'bitsandbytes'>,\n",
       " 'load_in_8bit': False,\n",
       " 'load_in_4bit': True,\n",
       " 'llm_int8_threshold': 6.0,\n",
       " 'llm_int8_skip_modules': None,\n",
       " 'llm_int8_enable_fp32_cpu_offload': False,\n",
       " 'llm_int8_has_fp16_weight': False,\n",
       " 'bnb_4bit_quant_type': 'nf4',\n",
       " 'bnb_4bit_use_double_quant': False,\n",
       " 'bnb_4bit_compute_dtype': 'float16'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.quantization_config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf31cc51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:11:19.789271Z",
     "iopub.status.busy": "2023-12-14T04:11:19.788577Z",
     "iopub.status.idle": "2023-12-14T04:11:19.794437Z",
     "shell.execute_reply": "2023-12-14T04:11:19.793412Z",
     "shell.execute_reply.started": "2023-12-14T04:11:19.789238Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_r = 8                  # @param {type:\"integer\"}\n",
    "lora_alpha = 32             # @param {type:\"integer\"}\n",
    "lora_dropout = 0.05         # @param {type:\"number\"}\n",
    "bias = \"none\"               # @param [\"all\", \"none\"]\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=bias,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b2a0d43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:11:22.366847Z",
     "iopub.status.busy": "2023-12-14T04:11:22.366117Z",
     "iopub.status.idle": "2023-12-14T04:11:22.372828Z",
     "shell.execute_reply": "2023-12-14T04:11:22.371708Z",
     "shell.execute_reply.started": "2023-12-14T04:11:22.366815Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @markdown ### Enter a file path:\n",
    "OUTPUT_DIR = \"experiments\"          # @param {type:\"string\"}\n",
    "\n",
    "# @markdown ---\n",
    "per_device_train_batch_size = 4     # @param {type:\"integer\"}\n",
    "gradient_accumulation_steps = 4     # @param {type:\"integer\"}\n",
    "optim = \"paged_adamw_32bit\"         # @param {type:\"string\"}\n",
    "logging_steps = 10                  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-4                # @param {type:\"number\"}\n",
    "max_grad_norm = 0.3                 # @param {type:\"number\"}\n",
    "num_train_epochs = 5                # @param {type:\"integer\"}\n",
    "evaluation_strategy = \"steps\"       # @param {type:\"string\"}\n",
    "eval_steps = 0.2                    # @param {type:\"number\"}\n",
    "warmup_ratio = 0.05                 # @param {type:\"number\"}\n",
    "save_strategy = \"epoch\"             # @param {type:\"string\"}\n",
    "lr_scheduler_type = \"cosine\"        # @param {type:\"string\"}\n",
    "fp16=True                           # @param {type:\"boolean\"}\n",
    "group_by_length = True              # @param {type:\"boolean\"}\n",
    "save_safetensors = True             # @param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "048c909c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:11:27.264610Z",
     "iopub.status.busy": "2023-12-14T04:11:27.263668Z",
     "iopub.status.idle": "2023-12-14T04:11:27.271915Z",
     "shell.execute_reply": "2023-12-14T04:11:27.270918Z",
     "shell.execute_reply.started": "2023-12-14T04:11:27.264573Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=fp16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    evaluation_strategy=evaluation_strategy,\n",
    "    eval_steps=eval_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    save_strategy=save_strategy,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"none\",\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b08a7faa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:20:35.122436Z",
     "iopub.status.busy": "2023-12-14T04:20:35.122023Z",
     "iopub.status.idle": "2023-12-14T04:20:35.676830Z",
     "shell.execute_reply": "2023-12-14T04:20:35.675776Z",
     "shell.execute_reply.started": "2023-12-14T04:20:35.122404Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc646d8e044e489b984ec5447f7260cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/79 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f7246f515441c0b9cb378911389b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=combine_dataset[\"train\"],\n",
    "    eval_dataset=combine_dataset[\"validation\"],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=4096,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d953eb84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:20:40.001982Z",
     "iopub.status.busy": "2023-12-14T04:20:40.001624Z",
     "iopub.status.idle": "2023-12-14T05:58:29.562539Z",
     "shell.execute_reply": "2023-12-14T05:58:29.561632Z",
     "shell.execute_reply.started": "2023-12-14T04:20:40.001957Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.463979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.643400</td>\n",
       "      <td>0.143685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.643400</td>\n",
       "      <td>0.126721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.113081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.111951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25, training_loss=0.3292609858512878, metrics={'train_runtime': 24.7206, 'train_samples_per_second': 15.979, 'train_steps_per_second': 1.011, 'total_flos': 1120306672852992.0, 'train_loss': 0.3292609858512878, 'epoch': 5.0})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "072eec94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T05:58:55.827012Z",
     "iopub.status.busy": "2023-12-14T05:58:55.826631Z",
     "iopub.status.idle": "2023-12-14T05:58:55.925788Z",
     "shell.execute_reply": "2023-12-14T05:58:55.924781Z",
     "shell.execute_reply.started": "2023-12-14T05:58:55.826980Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daae7660",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!zip -r /kaggle/working/experiments.zip /kaggle/working/experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54cc2fb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Inference with Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "769928f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:05:39.779813Z",
     "iopub.status.busy": "2023-12-14T06:05:39.779129Z",
     "iopub.status.idle": "2023-12-14T06:05:39.921532Z",
     "shell.execute_reply": "2023-12-14T06:05:39.920779Z",
     "shell.execute_reply.started": "2023-12-14T06:05:39.779779Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "KAGGLE_OUTPUT_DIR = \"./experiments\"\n",
    "model = PeftModel.from_pretrained(model, KAGGLE_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c615a68e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "138a1a19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:05:42.178074Z",
     "iopub.status.busy": "2023-12-14T06:05:42.177673Z",
     "iopub.status.idle": "2023-12-14T06:05:42.183529Z",
     "shell.execute_reply": "2023-12-14T06:05:42.182574Z",
     "shell.execute_reply.started": "2023-12-14T06:05:42.178042Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ต๊อบชอบไปไหน\n"
     ]
    }
   ],
   "source": [
    "example = test_df.iloc[0]\n",
    "print(example.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b352c08b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:05:57.508120Z",
     "iopub.status.busy": "2023-12-14T06:05:57.507247Z",
     "iopub.status.idle": "2023-12-14T06:09:41.573793Z",
     "shell.execute_reply": "2023-12-14T06:09:41.572773Z",
     "shell.execute_reply.started": "2023-12-14T06:05:57.508085Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 111 ms, sys: 243 ms, total: 354 ms\n",
      "Wall time: 353 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = generate_answer(model, example.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "43ba664c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:10:17.981515Z",
     "iopub.status.busy": "2023-12-14T06:10:17.980858Z",
     "iopub.status.idle": "2023-12-14T06:10:17.986442Z",
     "shell.execute_reply": "2023-12-14T06:10:17.985587Z",
     "shell.execute_reply.started": "2023-12-14T06:10:17.981484Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n"
     ]
    }
   ],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "308628ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:10:23.032475Z",
     "iopub.status.busy": "2023-12-14T06:10:23.032087Z",
     "iopub.status.idle": "2023-12-14T06:10:23.037497Z",
     "shell.execute_reply": "2023-12-14T06:10:23.036591Z",
     "shell.execute_reply.started": "2023-12-14T06:10:23.032444Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ชื่อต๊อบ'\n"
     ]
    }
   ],
   "source": [
    "pprint(example.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fcf624",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7b35253c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:10:29.786936Z",
     "iopub.status.busy": "2023-12-14T06:10:29.786559Z",
     "iopub.status.idle": "2023-12-14T06:10:29.792825Z",
     "shell.execute_reply": "2023-12-14T06:10:29.791719Z",
     "shell.execute_reply.started": "2023-12-14T06:10:29.786905Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ชื่ออะไร\n"
     ]
    }
   ],
   "source": [
    "example = test_df.iloc[3]\n",
    "print(example.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7157310e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:10:31.380560Z",
     "iopub.status.busy": "2023-12-14T06:10:31.380177Z",
     "iopub.status.idle": "2023-12-14T06:10:31.934009Z",
     "shell.execute_reply": "2023-12-14T06:10:31.933042Z",
     "shell.execute_reply.started": "2023-12-14T06:10:31.380530Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 118 ms, sys: 238 ms, total: 356 ms\n",
      "Wall time: 355 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = generate_answer(model, example.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a76d309c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:10:34.678076Z",
     "iopub.status.busy": "2023-12-14T06:10:34.677702Z",
     "iopub.status.idle": "2023-12-14T06:10:34.682895Z",
     "shell.execute_reply": "2023-12-14T06:10:34.682028Z",
     "shell.execute_reply.started": "2023-12-14T06:10:34.678049Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n"
     ]
    }
   ],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "acf54cbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:10:36.662851Z",
     "iopub.status.busy": "2023-12-14T06:10:36.662451Z",
     "iopub.status.idle": "2023-12-14T06:10:36.668371Z",
     "shell.execute_reply": "2023-12-14T06:10:36.667311Z",
     "shell.execute_reply.started": "2023-12-14T06:10:36.662818Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ชื่อต๊อบ'\n"
     ]
    }
   ],
   "source": [
    "pprint(example.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5b25d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b8870bd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:10:38.506826Z",
     "iopub.status.busy": "2023-12-14T06:10:38.506445Z",
     "iopub.status.idle": "2023-12-14T06:10:38.512171Z",
     "shell.execute_reply": "2023-12-14T06:10:38.511235Z",
     "shell.execute_reply.started": "2023-12-14T06:10:38.506796Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ต๊อบสูงเท่าไหร่\n"
     ]
    }
   ],
   "source": [
    "example = test_df.iloc[2]\n",
    "print(example.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "209d84a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:10:50.772574Z",
     "iopub.status.busy": "2023-12-14T06:10:50.771879Z",
     "iopub.status.idle": "2023-12-14T06:14:14.491028Z",
     "shell.execute_reply": "2023-12-14T06:14:14.490041Z",
     "shell.execute_reply.started": "2023-12-14T06:10:50.772544Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 99.4 ms, sys: 17 ms, total: 116 ms\n",
      "Wall time: 116 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = generate_answer(model, example.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6f9a39d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:16:01.594219Z",
     "iopub.status.busy": "2023-12-14T06:16:01.593533Z",
     "iopub.status.idle": "2023-12-14T06:16:01.599236Z",
     "shell.execute_reply": "2023-12-14T06:16:01.598372Z",
     "shell.execute_reply.started": "2023-12-14T06:16:01.594187Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n"
     ]
    }
   ],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0732dbf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:16:03.984315Z",
     "iopub.status.busy": "2023-12-14T06:16:03.983955Z",
     "iopub.status.idle": "2023-12-14T06:16:03.989596Z",
     "shell.execute_reply": "2023-12-14T06:16:03.988781Z",
     "shell.execute_reply.started": "2023-12-14T06:16:03.984287Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'173'\n"
     ]
    }
   ],
   "source": [
    "pprint(example.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd28da5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### General Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "41b70b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:16:26.523657Z",
     "iopub.status.busy": "2023-12-14T06:16:26.523265Z",
     "iopub.status.idle": "2023-12-14T06:18:46.632132Z",
     "shell.execute_reply": "2023-12-14T06:18:46.631056Z",
     "shell.execute_reply.started": "2023-12-14T06:16:26.523626Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " 'ต๊อบชอบอะไรบ้าง\\n'\n",
      " '\\n'\n",
      " '### ต๊อกชอบกินอะไรมากที่สุด\\n'\n",
      " ' ตอบ\\n'\n",
      " 'ถั่ว\\n'\n",
      " 'น้ำ\\n'\n",
      " 'อะไรตอกกินมาก\\n'\n",
      " 'คำตอบคือต็อก\\n'\n",
      " 'คือถ๊วย\\n'\n",
      " 'ชื่อต๋๊ง\\n'\n",
      " 'ชอบถ้วยต้ม\\n'\n",
      " 'กินตับตอย\\n'\n",
      " 'ไปตากา\\n'\n",
      " 'ต่อไปต๊ะตอง\\n'\n",
      " 'ข้างต้านต้า\\n'\n",
      " 'ตามตึ๊กตี้\\n'\n",
      " 'ต่อต้วนตำติน\\n'\n",
      " 'ดังต้อตอ\\n'\n",
      " 'ก่อนตางตี\\n'\n",
      " 'หลังติงต้ง\\n'\n",
      " 'ซ้อนตงตุมต\\n'\n",
      " 'ไถตถงถ\\n'\n",
      " 'ตีตต้อยตาตายตฺตี่ตอนตือตูตานตาสตั๊ตติตรอต้อน\\n'\n",
      " 'แต่ตลกติ่งตอดตวน\\n'\n",
      " 'แต่อ้ตค๊อตโตตาร\\n'\n",
      " 'ไม่ตกลงตัวต่าต้างต่านตู้ติตุนตื่ตูกต่ายต่าวต้าวตาวตวงตามตุกตอลตัสต้องตังตอบติบตรตรีตราตริตรมตมตวะตุตักตอมตํ')\n",
      "CPU times: user 10.1 s, sys: 1.1 s, total: 11.3 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"ชื่ออะไร\"\n",
    "response = generate_answer(model, question)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b67f4c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T06:18:46.634826Z",
     "iopub.status.busy": "2023-12-14T06:18:46.634119Z",
     "iopub.status.idle": "2023-12-14T06:19:23.574131Z",
     "shell.execute_reply": "2023-12-14T06:19:23.573161Z",
     "shell.execute_reply.started": "2023-12-14T06:18:46.634786Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " 'คุณต๊อกสูง 180 เซนติเมตร\\n'\n",
      " 'ต็อบต๋อยสูงแค่ไหน\\n'\n",
      " 'เราตอกต๊ะสูง\\n'\n",
      " '\\n'\n",
      " 'คำตอบคือ: 2\\n'\n",
      " 'คือต้อต้อกระเป๋าต้งตากตางตงตองตอตตุมตอนตานตา')\n",
      "CPU times: user 3.07 s, sys: 534 ms, total: 3.6 s\n",
      "Wall time: 3.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"ต๊อบสูงเท่าไหร่\"\n",
    "response = generate_answer(model, question)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307fc68d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4157536,
     "sourceId": 7190406,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30616,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-14T06:20:55.952820",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
